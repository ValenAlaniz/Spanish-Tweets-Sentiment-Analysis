{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-4azOYi8KSoC"
   },
   "source": [
    "# Laboratorio de Introducción al Procesamiento de Lenguaje Natural\n",
    "\n",
    "# Tarea 2\n",
    "\n",
    "El objetivo de este laboratorio es realizar diferentes experimentos para representar y clasificar textos. Para esto se trabajará con un corpus para análisis de sentimiento, creado para la competencia [TASS 2020](http://www.sepln.org/workshops/tass/) (IberLEF - SEPLN).\n",
    "\n",
    "### Entrega\n",
    "Deberán entregar un archivo *.ipynb* con su solución, que incluya código, comentarios y respuestas a las preguntas que se incluyen al final de este notebook.\n",
    "\n",
    "El plazo de entrega de la tarea 2 cierra el **20 de junio a las 23:59 horas**.\n",
    "\n",
    "### Plataforma sugerida\n",
    "Sugerimos que utilicen la plataforma [Google colab](https://colab.research.google.com/), que permite trabajar colaborativamente con un *notebook* de python. Al finalizar pueden descargar ese *notebook* en un archivo .ipynb, incluyendo las salidas ya ejecutadas, con la opción ```File -> Download -> Download .ipynb```.\n",
    "\n",
    "### Aprobación del laboratorio\n",
    "Para aprobar el laboratorio se exige como mínimo:\n",
    "* Probar dos enfoques diferentes para la representación de tweets (uno basado en BoW y otro en word embeddings)\n",
    "* Probar al menos dos modelos de aprendizaje automático con cada representación\n",
    "* Comparar los resultados con los obtenidos por el modelo de pysentimiento.\n",
    "El preprocesamiento, las pruebas con otras formas de representación de los tweets, los experimentos con otros modelos de aprendizaje automático, incluyendo aprendizaje profundo, entre otros posibles experimentos, no son requisito para aprobar el laboratorio, aunque aportan a la nota final.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Grupo 02**\n",
    "- Natalie Valentina Alaniz Ferreira, natalie.alaniz@fing.edu.uy\n",
    "- Agustín Matías Martínez Acuña, agustin.martinez.acunaa@fing.edu.uy\n",
    "- Matías Fernando Rama Perdomo, matias.rama@fing.edu.uy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sAumcYFLP0f8"
   },
   "source": [
    "## Parte 1 - Carga y preprocesamiento del corpus\n",
    "\n",
    "Para trabajar en este notebook deben cargar los tres archivos disponbiles en eva: train.csv, devel.csv y test.csv.\n",
    "\n",
    "La aplicación de una etapa de preprocesamiento similar a la implementada en la tarea 1 es opcional. Es interesante hacer experimentos con y sin la etapa de preprocesamiento, de modo de comparar resultados (sobre el corpus de desarrollo, devel.csv) y definir si se incluye o no en la solución final.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Carga"
   ],
   "metadata": {
    "id": "Ix076JBqADzb"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "nnBJGtH5QLcA"
   },
   "outputs": [],
   "source": [
    "# Carga de los datasets\n",
    "import csv\n",
    "\n",
    "# Carga del archivo train.csv\n",
    "with open('datos/train.csv', newline='', encoding=\"utf-8\") as corpus_csv:\n",
    "    reader = csv.reader(corpus_csv)\n",
    "    next(reader) # Saltea el cabezal del archivo\n",
    "    train_set = [x for x in reader]\n",
    "\n",
    "# Carga del archivo devel.csv\n",
    "with open('datos/devel.csv', newline='', encoding=\"utf-8\") as corpus_csv:\n",
    "    reader = csv.reader(corpus_csv)\n",
    "    next(reader) # Saltea el cabezal del archivo\n",
    "    devel_set = [x for x in reader]\n",
    "\n",
    "# Carga del archivo test.csv\n",
    "with open('datos/test.csv', newline='', encoding=\"utf-8\") as corpus_csv:\n",
    "    reader = csv.reader(corpus_csv)\n",
    "    next(reader) # Saltea el cabezal del archivo\n",
    "    test_set = [x for x in reader]\n",
    "\n",
    "# Carga del archivo stop_words_esp_anasent.csv\n",
    "with open('datos/stop_words_esp_anasent.csv', newline='', encoding=\"utf-8\") as corpus_csv:\n",
    "    reader = csv.reader(corpus_csv)\n",
    "    next(reader) # Saltea el cabezal del archivo\n",
    "    stop_words_esp_anasent = [x[0] for x in reader]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preprocesamiento"
   ],
   "metadata": {
    "id": "wt3Ow8D8AIyw"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Algunos procedimientos y funciones auxiliares\n",
    "def imprimir_tweet_polaridad(tweet):\n",
    "  print(\"TWEET: \"+ tweet[1])\n",
    "  print(\"POLARIDAD: \"+ tweet[2])"
   ],
   "metadata": {
    "id": "tjjY9pRHZ7JH"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import re\n",
    "import random\n",
    "\n",
    "# Preprocesamiento de los tweets\n",
    "\n",
    "# Definición de las sustituciones a realizar\n",
    "expresiones = [[r'#\\w+','HASHTAG'],\n",
    "                  [r'http\\S+', 'URL'], ['\\?\\?*', '?'],\n",
    "                  [r'\\!\\!*', '!'],['@\\w+', 'USUARIO'],\n",
    "                  [r'\\?', '? '],\n",
    "                  ['!', '! '],\n",
    "                  [',', ', '],\n",
    "                  [' ,', ','],\n",
    "                  [r'(?<!\\.)\\.(?!\\.)', '. '],\n",
    "                  [' q ', ' que '],\n",
    "                  [' ke ', ' que '],\n",
    "                  [' Q ', ' Que '],\n",
    "                  [' d ', ' de '],\n",
    "                  [r' (xq|pq) ', ' porque '],\n",
    "                  [' XQ ', ' porque '],\n",
    "                  [' m ', ' me '],\n",
    "                  [' m ', ' me '],\n",
    "                  ['M ', 'Me '],\n",
    "                  [' x ', ' por '],\n",
    "                  [r' (porfis|porfa|xfa) ', ' por favor '],\n",
    "                  [r'\\b(?:a*ja+j[aj]*)+\\b', 'jaja'],\n",
    "                  [r'\\b(?:a*ha+h[ah]*)+\\b', 'jaja'],\n",
    "                  [r'(?i) ud(\\. | )', ' Usted '],\n",
    "                  [r'(?i) uds(\\. | )', ' Ustedes '],\n",
    "                  ['\\.(\\.)+', '...'],\n",
    "                  [r'\\s(\\s)+', ' '],\n",
    "                  [':', ': ']\n",
    "                  ]\n",
    "\n",
    "# Se aplican todas las sustituciones definidas en \"expresiones\"\n",
    "def preprocesar_texto(texto):\n",
    "    for norm in expresiones:\n",
    "        texto = re.sub(str(norm[0]), str(norm[1]), texto)\n",
    "    return texto\n",
    "\n",
    "def preproc_dataset(dataset):\n",
    "  res = []\n",
    "  for twit in dataset:\n",
    "    twit_preproc = preprocesar_texto(twit[1])\n",
    "    res.append([twit[0], twit_preproc, twit[2]])\n",
    "  return res\n",
    "\n",
    "# Variables globales para los conjuntos preprocesados\n",
    "train_set_preproc = preproc_dataset(train_set)\n",
    "devel_set_preproc = preproc_dataset(devel_set)\n",
    "test_set_preproc = preproc_dataset(test_set)\n",
    "\n",
    "# Un ejemplo de train_set_preproc para corroborar que esté andando\n",
    "imprimir_tweet_polaridad(random.choice(train_set_preproc))\n"
   ],
   "metadata": {
    "id": "T2kOeMA_ly_b",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "eb2999c8-63db-4c94-fc79-18aaefbab705"
   },
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TWEET: Sssh, creo que estoy viendo a los Reyes... Pero, que hacen? Llevan palanquetas y los sacos vacíos, espera! Están llevándose la cuberteria! \n",
      "POLARIDAD: NONE\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YZMlbsw2uFLm"
   },
   "source": [
    "## Parte 2 - Representación de los tweets\n",
    "\n",
    "Para representar los tweets se pide que experimenten con modelos basados en Bag of Words (BoW) y con Word Embeddings.\n",
    "\n",
    "Para los dos enfoques podrán elegir entre diferentes opciones:\n",
    "\n",
    "**Bag of Words**\n",
    "\n",
    "* BOW estándar: se recomienda trabajar con la clase [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) de sklearn, en particular, fit_transform y transform.\n",
    "* BOW filtrando stop-words: tienen disponible en eva una lista de stop-words para el español, adaptada para análisis de sentimiento (no se filtran palabras relevantes para determinar la polaridad, como \"no\", \"pero\", etc.).\n",
    "* BoW usando lemas: pueden usar herramientas de spacy.\n",
    "* BOW seleccionando las features más relevantes: se recomienda usar la clase [SelectKBest](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html?highlight=select%20k%20best#sklearn.feature_selection.SelectKBest) y probar con diferentes valores de k (por ejemplo, 10, 50, 200, 1000).\n",
    "* BOW combinado con TF-IDF: se recomienda usar la clase [TfidfVectorizer](https://https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)\n",
    "\n",
    "**Word Embeddings**\n",
    "\n",
    "* A partir de los word embeddings, representar cada tweet como el vector promedio (mean vector) de los vectores de las palabras que lo componen.\n",
    "* A partir de los word embeddings, representar cada tweet como la concatenación de los vectores de las palabras que lo componen (llevando el vector total a un largo fijo).\n",
    "\n",
    "Se recomienda trabajar con alguna de las colecciones de word embeddings disponibles en https://github.com/dccuchile/spanish-word-embeddings. El repositorio incluye links a ejemplos y tutoriales.\n",
    "\n",
    "\n",
    "Se pide que prueben al menos una opción basada en BoW y una basada en word embeddings."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models.keyedvectors import KeyedVectors"
   ],
   "metadata": {
    "id": "Yy2afQwMX2r0"
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Representación BoW"
   ],
   "metadata": {
    "id": "G3tFcmytep5H"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def tweets_from_corpus(corpus):\n",
    "     return [tuits[1] for tuits in corpus]"
   ],
   "metadata": {
    "id": "Eiyoa6FoBoIN"
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### BoW Estándar"
   ],
   "metadata": {
    "id": "g1ySO9kee6dG"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def representar_en_bow(frase, vectorizer):\n",
    "    return vectorizer.transform([frase])"
   ],
   "metadata": {
    "id": "lJJieI-p07jE"
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "G9BNltLduHqB"
   },
   "outputs": [],
   "source": [
    "def bow_standard(corpus):\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "    return vectorizer, X.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### BOW filtrando stop-words"
   ],
   "metadata": {
    "id": "vGBfezmce_gV"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def corpus_to_bow_stopwords(corpus):\n",
    "    vectorizer = CountVectorizer(stop_words=stop_words_esp_anasent)\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "    return vectorizer , X.toarray()"
   ],
   "metadata": {
    "id": "KCZtef8UfLy9"
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### BoW combinado con TF-IDF"
   ],
   "metadata": {
    "id": "4hTwjI1ZfETc"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Representación Word Embedding"
   ],
   "metadata": {
    "id": "x0Bo2hGfeuP8"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def corpus_to_bow_tf_idf(corpus):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "    return vectorizer, X.toarray()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Representación de los tweets usando word embeddings\n",
    "wordvectors_file_vec = 'embeddings-l-model.vec'\n",
    "cantidad = 100000\n",
    "wordvectors = KeyedVectors.load_word2vec_format(wordvectors_file_vec, limit=cantidad)"
   ],
   "metadata": {
    "id": "K_T2KWO4RFIV"
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### WE Mean Vector"
   ],
   "metadata": {
    "id": "CN9OuxV7fixy"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Representación de los tweets usando word embeddings representando cada tweet como el vector promedio (mean vector) de los vectores de las palabras que lo componen.\n",
    "def mean_vector(tweet,sin_stop_words, pre_procesado, largo_vector):\n",
    "    words_vectors = []\n",
    "    for word in tweet.split():\n",
    "        if sin_stop_words and word in stop_words_esp_anasent:\n",
    "            continue\n",
    "\n",
    "        if pre_procesado:\n",
    "            word = preprocesar_texto(word)\n",
    "\n",
    "        if word in wordvectors.key_to_index.keys():\n",
    "            words_vectors.append(wordvectors[word])\n",
    "\n",
    "    if len(words_vectors) == 0:\n",
    "        mean_vector = np.zeros(largo_vector)\n",
    "    else:\n",
    "        mean_vector = np.mean(words_vectors, axis=0)[0:largo_vector]\n",
    "    return mean_vector\n"
   ],
   "metadata": {
    "id": "3xNsCI7dXTRe"
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### WE Concatenación de Vectores"
   ],
   "metadata": {
    "id": "Hg-sOzEHfobd"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ZFyYXHmUWHr2"
   },
   "outputs": [],
   "source": [
    "def representar_tuit_concatvec_we(tuit, tamanio_rep):\n",
    "    palabras = tuit.split()\n",
    "    rep = []\n",
    "    for word in palabras:\n",
    "        # Hay que ver que hacer con las palabras que no tienen representación, las estamos ignorando\n",
    "        # pero se puede asignarle a las ignoradas un vector fijo por ej [0,0,0,...,0]\n",
    "        if word in wordvectors:\n",
    "            word_vector = wordvectors[word][:tamanio_rep]\n",
    "        else:\n",
    "            word_vector = np.zeros(tamanio_rep)\n",
    "        rep.extend(word_vector)\n",
    "    return rep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pxAcPhqgWHr2"
   },
   "source": [
    "## Parte 3 - Clasificación de los tweets\n",
    "\n",
    "Para la clasificación de los tweets es posible trabajar con dos enfoques diferentes:\n",
    "\n",
    "* Aprendizaje Automático basado en atributos: se pide probar al menos dos modelos diferentes, por ejemplo, Multi Layer Perceptron ([MLP](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier)) y Support Vector Machines ([SVM](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)), y usar al menos dos formas de representación de tweets (una basada en BoW y otra basada en word embeddings). Se publicó en eva un léxico de palabras positivas y negativas que puede ser utilizado para generar atributos.\n",
    "\n",
    "* Aprendizaje Profundo: se recomienda experimentar con alguna red recurrente como LSTM. En este caso deben representar los tweets an base a word embeddings.\n",
    "\n",
    "Deberán usar el corpus de desarrollo (devel.csv) para comparar resultados de diferentes experimentos, variando los valores de los hiperparámetros, la forma de representación de los tweets, el preprocesamiento, los modelos de AA, etc.\n",
    "\n",
    "Tanto para la evaluación sobre desarrollo como para la evaluación final sobre test se usará la medida [Macro-F1](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html) (promedio de la medida F1 de cada clase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "W9FFTkuWWHr3"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from pysentimiento import create_analyzer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Variables globales para los clasificadores\n",
    "plt.style.use('fivethirtyeight')\n",
    "sentimiento_map = {\"NEU\": \"NONE\", \"NEG\": \"N\", \"POS\": \"P\"}\n",
    "tamanio = 100\n",
    "cantidad_entradas_vec_tuit = 300\n",
    "tamanio_vec_concat_we = 80"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Funciones auxiliares para generar los array de datos junto con sus polaridades para cada enfoque\n",
    "def generar_datos_polaridad_concatvec_we(tamanio_rep_palabras, cantidad_palabras_tuit, corpus):\n",
    "    polaridad = []\n",
    "    datos = []\n",
    "\n",
    "    for entrada in  corpus:\n",
    "        vec_entrada = representar_tuit_concatvec_we(entrada[1].lower(),tamanio_rep_palabras)\n",
    "        #Hago esto por si se pasa de largo\n",
    "        vec_entrada = vec_entrada[0:min(len(vec_entrada), cantidad_palabras_tuit)]\n",
    "        datos.append(vec_entrada)\n",
    "\n",
    "        polaridad.append(entrada[2])\n",
    "\n",
    "    datos_padded = [np.pad(vec, (0, cantidad_palabras_tuit - len(vec)), mode='constant') for vec in datos]\n",
    "\n",
    "    datos = np.vstack(datos_padded)\n",
    "    polaridad = np.array(polaridad)\n",
    "    return datos, polaridad\n",
    "\n",
    "def generar_datos_polaridad_mean_vector_we(cantidad_entradas_vec, sin_stop_words, pre_procesado, corpus):\n",
    "    polaridad = []\n",
    "    datos = []\n",
    "\n",
    "    for entrada in corpus:\n",
    "        vec_entrada = mean_vector(entrada[1].lower(), sin_stop_words, pre_procesado, cantidad_entradas_vec)\n",
    "\n",
    "        vec_entrada = np.array(vec_entrada)\n",
    "\n",
    "        vec_entrada = vec_entrada[0:cantidad_entradas_vec]\n",
    "        polaridad.append(entrada[2])\n",
    "        datos.append(vec_entrada)\n",
    "\n",
    "    polaridad = np.array(polaridad)\n",
    "    return datos, polaridad\n",
    "\n",
    "def generar_datos_polaridad_bow_stopwords(corpus, vectorizer):\n",
    "    polaridad = []\n",
    "    datos = []\n",
    "    for entrada in corpus:\n",
    "        vec_entrada = representar_en_bow(entrada[1].lower(), vectorizer)\n",
    "        vec_entrada = vec_entrada.toarray()\n",
    "        polaridad.append(entrada[2])\n",
    "        datos.append(vec_entrada)\n",
    "\n",
    "    datos = np.concatenate(datos, axis=0)\n",
    "    polaridad = np.array(polaridad)\n",
    "    return datos, polaridad\n",
    "\n",
    "def generar_array_polaridad(corpus):\n",
    "    return [x[2] for x in corpus]"
   ],
   "metadata": {
    "id": "mRXkXjwJqkEs"
   },
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Experimentos MLP"
   ],
   "metadata": {
    "id": "Xtq7Fy-LOhgT"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### MLP utilizando BoW stopwords"
   ],
   "metadata": {
    "id": "wCEupw52OyGr"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def entrenar_mlp_bow_stopwords(corpus, vectorizer):\n",
    "    datos, polaridad = generar_datos_polaridad_bow_stopwords(corpus, vectorizer)\n",
    "    clf = MLPClassifier(random_state=1, max_iter=300)\n",
    "    clf.fit(datos, polaridad)\n",
    "    return clf"
   ],
   "metadata": {
    "id": "Ii0VqnkOO3x8"
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Test MLP BoW Stopwords\n",
    "\n",
    "def macroF1_bow(clf, vectorizer, corpus):\n",
    "    datos, y_real = generar_datos_polaridad_bow_stopwords(corpus, vectorizer)\n",
    "    y_pred = [clf.predict(representacion_tuit.reshape(1, -1)) for representacion_tuit in datos]\n",
    "\n",
    "    return f1_score(y_real, y_pred, average=\"macro\")"
   ],
   "metadata": {
    "id": "UitZBpL_vnYZ"
   },
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### MLP utilizando Mean Vector (WE)"
   ],
   "metadata": {
    "id": "oXSZAfUayDBw"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def entrenar_mlp_mean_vector(cantidad_entradas_vec, sin_stop_words, pre_procesado, corpus):\n",
    "  clf = MLPClassifier(random_state=1, max_iter=30000)\n",
    "  datos, polaridad = generar_datos_polaridad_mean_vector_we(cantidad_entradas_vec,sin_stop_words, pre_procesado, corpus)\n",
    "  clf.fit(datos, polaridad)\n",
    "\n",
    "  return clf"
   ],
   "metadata": {
    "id": "6JOo9d1Eq2LJ"
   },
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Experimentos SVM"
   ],
   "metadata": {
    "id": "7R0rlZMhednn"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### SVM utilizando WE"
   ],
   "metadata": {
    "id": "7fYJ3fIPOPq4"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### SVM con concatenación de vectores"
   ],
   "metadata": {
    "id": "s_PXrqfFcIGr"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def entrenar_svm_concatvec(tamanio_rep_palabras, cantidad_palabras_tuit,  corpus):\n",
    "    clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "    datos, polaridad = generar_datos_polaridad_concatvec_we(tamanio_rep_palabras, cantidad_palabras_tuit, corpus)\n",
    "    clf.fit(datos, polaridad)\n",
    "    return clf"
   ],
   "metadata": {
    "id": "ZTPJtTCVuxj8"
   },
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Test SVM con concatvec\n",
    "def predecir_polaridad_concat(tuit, cantidad_entradas_vec, clf):\n",
    "    if cantidad_entradas_vec - len(tuit) < 0:\n",
    "        tuit = tuit[0:cantidad_entradas_vec]\n",
    "    else:\n",
    "        tuit = np.pad(\n",
    "            tuit,\n",
    "            (0, cantidad_entradas_vec - len(tuit)),\n",
    "            mode=\"constant\",\n",
    "        )\n",
    "    return clf.predict([tuit])\n",
    "\n",
    "def macro_F1_concatvec_we(tamanio_rep_palabras, cantidad_entradas_vec, clf, corpus):\n",
    "    datos, y_real = generar_datos_polaridad_concatvec_we(tamanio_rep_palabras, cantidad_entradas_vec, corpus)\n",
    "    y_pred = [predecir_polaridad_concat(x, cantidad_entradas_vec, clf) for x in datos]\n",
    "    return f1_score(y_real, y_pred, average=\"macro\")"
   ],
   "metadata": {
    "id": "UvKtcEQBqv96"
   },
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### SVM con Mean Vector"
   ],
   "metadata": {
    "id": "LuML6RMLcSot"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# SVM Mean Vector\n",
    "def entrenar_svm_mean_vector(cantidad_entradas_vec,sin_stop_words, pre_procesado, corpus):\n",
    "    clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "    datos, polaridad = generar_datos_polaridad_mean_vector_we(cantidad_entradas_vec,sin_stop_words, pre_procesado, corpus)\n",
    "    clf.fit(datos, polaridad)\n",
    "    return clf"
   ],
   "metadata": {
    "id": "9-NMtzzRrFvx"
   },
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def predecir_polaridad_mean_vector(tuit, cantidad_entradas_vec, clf):\n",
    "    if cantidad_entradas_vec - len(tuit) < 0:\n",
    "        representacion_tuit = tuit[0:cantidad_entradas_vec]\n",
    "    else:\n",
    "        representacion_tuit = np.pad(\n",
    "           tuit,\n",
    "            (0, cantidad_entradas_vec - len(tuit)),\n",
    "            mode=\"constant\",\n",
    "        )\n",
    "    return clf.predict([representacion_tuit])\n",
    "\n",
    "def macro_F1_mean_vector(cantidad_entradas_vec,sin_stop_words, pre_procesado, clf, corpus):\n",
    "    datos, y_real = generar_datos_polaridad_mean_vector_we(cantidad_entradas_vec, sin_stop_words, pre_procesado, corpus)\n",
    "    y_pred = [predecir_polaridad_mean_vector(x, cantidad_entradas_vec, clf) for x in datos]\n",
    "    return f1_score(y_real, y_pred, average=\"macro\")\n",
    "\n",
    "def accuracy_score_mean_vector(cantidad_entradas_vec,sin_stop_words, pre_procesado, clf, corpus):\n",
    "    datos, y_real = generar_datos_polaridad_mean_vector_we(cantidad_entradas_vec, sin_stop_words, pre_procesado, corpus)\n",
    "    y_pred = [predecir_polaridad_mean_vector(x, cantidad_entradas_vec, clf) for x in datos]\n",
    "    return accuracy_score(y_real, y_pred)"
   ],
   "metadata": {
    "id": "SL3BmrS8smjg"
   },
   "execution_count": 77,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ensamble Voting de SVM y MLP"
   ],
   "metadata": {
    "id": "RKy9LcHpvJKL"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Ensamble Voting de SVM y MLP\n",
    "def entrenar_ensamblado_de_votacion_svm_mlp(cantidad_entradas_vec, sin_stop_words, pre_procesado, corpus):\n",
    "  clf_svm = entrenar_svm_mean_vector(cantidad_entradas_vec,sin_stop_words, pre_procesado, corpus)\n",
    "  clf_mlp = entrenar_mlp_mean_vector(cantidad_entradas_vec,sin_stop_words, pre_procesado, corpus)\n",
    "  datos, polaridad = generar_datos_polaridad_mean_vector_we(cantidad_entradas_vec,sin_stop_words, pre_procesado, corpus)\n",
    "\n",
    "  clf_votacion = VotingClassifier(estimators=[('svm', clf_svm), ('mlp', clf_mlp)], voting='hard')\n",
    "  clf_votacion.fit(datos, polaridad)\n",
    "\n",
    "  return clf_votacion"
   ],
   "metadata": {
    "id": "A21a3nTXrC7J"
   },
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Resultados de los experimentos"
   ],
   "metadata": {
    "id": "OTQwj7uZcxXg"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "# MLP con BoW Entrenamiento\n",
    "\n",
    "vectorizer_bow_sw, x_sw = corpus_to_bow_stopwords(tweets_from_corpus(train_set))\n",
    "clf_mlp_bow_stopwords = entrenar_mlp_bow_stopwords(train_set, vectorizer_bow_sw)\n",
    "\n",
    "vectorizer_bow_tf_idf, x_tf_idf = corpus_to_bow_tf_idf(tweets_from_corpus(train_set))\n",
    "clf_mlp_bow_tf_idf = entrenar_mlp_bow_stopwords(train_set, vectorizer_bow_tf_idf)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP utilizando BoW\n",
      "╒════════════╤════════════╕\n",
      "│            │   Macro F1 │\n",
      "╞════════════╪════════════╡\n",
      "│ BoW sin SW │    0.55153 │\n",
      "├────────────┼────────────┤\n",
      "│ BoW TF-IDF │    0.55004 │\n",
      "╘════════════╧════════════╛\n"
     ]
    }
   ],
   "source": [
    "# MLP con BoW\n",
    "res = []\n",
    "headers = ['', 'Macro F1']\n",
    "\n",
    "macroF1_bow_sw =  macroF1_bow(clf_mlp_bow_stopwords, vectorizer_bow_sw, devel_set)\n",
    "res.append([\"BoW sin SW\", macroF1_bow_sw])\n",
    "\n",
    "macroF1_bow_tf_idf = macroF1_bow(clf_mlp_bow_tf_idf, vectorizer_bow_tf_idf, devel_set)\n",
    "res.append([\"BoW TF-IDF\", macroF1_bow_tf_idf])\n",
    "\n",
    "print(\"MLP utilizando BoW\")\n",
    "print(tabulate(res, headers=headers, tablefmt='fancy_grid'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "entrenamiento_agrandado = np.concatenate((np.array(train_set),np.array(devel_set)), axis=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "# Entrenamiento MLP Mean Vector\n",
    "\n",
    "clf_mlp_mean_vector_sin_stop_words_preproc = entrenar_mlp_mean_vector(cantidad_entradas_vec_tuit, True, True, train_set)\n",
    "clf_mlp_mean_vector_sin_stop_words = entrenar_mlp_mean_vector(cantidad_entradas_vec_tuit ,True,False,train_set)\n",
    "clf_mlp_mean_vector_preproc = entrenar_mlp_mean_vector(cantidad_entradas_vec_tuit,False,True, train_set)\n",
    "clf_mlp_mean_vector = entrenar_mlp_mean_vector(cantidad_entradas_vec_tuit,False,False, train_set)\n",
    "\n",
    "clf_mlp_mean_vector_sin_stop_words_preproc_agrandado = entrenar_mlp_mean_vector(cantidad_entradas_vec_tuit, True, True, entrenamiento_agrandado)\n",
    "clf_mlp_mean_vector_sin_stop_words_agrandado = entrenar_mlp_mean_vector(cantidad_entradas_vec_tuit ,True,False,entrenamiento_agrandado)\n",
    "clf_mlp_mean_vector_preproc_agrandado = entrenar_mlp_mean_vector(cantidad_entradas_vec_tuit,False,True, entrenamiento_agrandado)\n",
    "clf_mlp_mean_vector_agrandado = entrenar_mlp_mean_vector(cantidad_entradas_vec_tuit,False,False, entrenamiento_agrandado)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# MLP con mean vector\n",
    "res = []\n",
    "headers = ['Sin SW', 'Pre-procesado', 'Macro F1']\n",
    "\n",
    "macro_f1_mlp_mean_vector_sin_stop_words_preproc = macro_F1_mean_vector(cantidad_entradas_vec_tuit, True, True, clf_mlp_mean_vector_sin_stop_words_preproc, devel_set)\n",
    "res.append([\"Sí\",\"Sí\", macro_f1_mlp_mean_vector_sin_stop_words_preproc])\n",
    "\n",
    "macro_f1_mlp_mean_vector_sin_stop_words = macro_F1_mean_vector(cantidad_entradas_vec_tuit,True,False, clf_mlp_mean_vector_sin_stop_words, devel_set)\n",
    "res.append([\"Sí\", \"No\", macro_f1_mlp_mean_vector_sin_stop_words])\n",
    "\n",
    "macro_f1_mlp_mean_vector_pre_proc =  macro_F1_mean_vector(cantidad_entradas_vec_tuit,False,True, clf_mlp_mean_vector_preproc, devel_set)\n",
    "res.append([\"No\", \"Sí\", macro_f1_mlp_mean_vector_pre_proc])\n",
    "\n",
    "macro_f1_mlp_mean_vector = macro_F1_mean_vector(cantidad_entradas_vec_tuit,False,False,clf_mlp_mean_vector, devel_set)\n",
    "res.append([\"No\", \"No\", macro_f1_mlp_mean_vector])\n",
    "\n",
    "print(\"MLP usando de entrenamiento train_set\")\n",
    "print(tabulate(res, headers=headers, tablefmt='fancy_grid'))\n",
    "\n",
    "# MLP Mean Vector agrandando el conjunto de entrenamiento\n",
    "res = []\n",
    "\n",
    "macro_f1_mlp_mean_vector_sin_stop_words_pre_proc_agrandado = macro_F1_mean_vector(cantidad_entradas_vec_tuit, True, True, clf_mlp_mean_vector_sin_stop_words_preproc_agrandado, test_set)\n",
    "res.append([\"Sí\",\"Sí\", macro_f1_mlp_mean_vector_sin_stop_words_pre_proc_agrandado])\n",
    "\n",
    "macro_f1_mlp_mean_vector_sin_stop_words_agrandado = macro_F1_mean_vector(cantidad_entradas_vec_tuit,True,False, clf_mlp_mean_vector_sin_stop_words_agrandado, test_set)\n",
    "res.append([\"Sí\", \"No\", macro_f1_mlp_mean_vector_sin_stop_words_agrandado])\n",
    "\n",
    "macro_f1_mlp_mean_vector_pre_proc_agrandado =  macro_F1_mean_vector(cantidad_entradas_vec_tuit,False,True, clf_mlp_mean_vector_preproc_agrandado, test_set)\n",
    "res.append([\"No\", \"Sí\", macro_f1_mlp_mean_vector_pre_proc_agrandado])\n",
    "\n",
    "macro_f1_mlp_mean_vector_agrandado = macro_F1_mean_vector(cantidad_entradas_vec_tuit,False,False,clf_mlp_mean_vector_agrandado, test_set)\n",
    "res.append([\"No\", \"No\", macro_f1_mlp_mean_vector_agrandado])\n",
    "\n",
    "print(\"MLP usando de entrenamiento train_set+devel_set (probado en test_set)\")\n",
    "print(tabulate(res, headers=headers, tablefmt='fancy_grid'))\n"
   ],
   "metadata": {
    "id": "EqYPHb9Icz09"
   },
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP usando de entrenamiento train_set\n",
      "╒══════════╤═════════════════╤════════════╕\n",
      "│ Sin SW   │ Pre-procesado   │   Macro F1 │\n",
      "╞══════════╪═════════════════╪════════════╡\n",
      "│ Sí       │ Sí              │   0.563197 │\n",
      "├──────────┼─────────────────┼────────────┤\n",
      "│ Sí       │ No              │   0.565241 │\n",
      "├──────────┼─────────────────┼────────────┤\n",
      "│ No       │ Sí              │   0.560286 │\n",
      "├──────────┼─────────────────┼────────────┤\n",
      "│ No       │ No              │   0.552427 │\n",
      "╘══════════╧═════════════════╧════════════╛\n",
      "MLP usando de entrenamiento train_set+devel_set (probado en test_set)\n",
      "╒══════════╤═════════════════╤════════════╕\n",
      "│ Sin SW   │ Pre-procesado   │   Macro F1 │\n",
      "╞══════════╪═════════════════╪════════════╡\n",
      "│ Sí       │ Sí              │   0.543757 │\n",
      "├──────────┼─────────────────┼────────────┤\n",
      "│ Sí       │ No              │   0.541133 │\n",
      "├──────────┼─────────────────┼────────────┤\n",
      "│ No       │ Sí              │   0.55644  │\n",
      "├──────────┼─────────────────┼────────────┤\n",
      "│ No       │ No              │   0.546341 │\n",
      "╘══════════╧═════════════════╧════════════╛\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# SVM concatenacion de vectores\n",
    "clf_svm_concatvec = entrenar_svm_concatvec(tamanio,tamanio_vec_concat_we, train_set)\n",
    "print(\"F1 Score SVM concatenacion de vectores: \", macro_F1_concatvec_we(tamanio, tamanio_vec_concat_we, clf_svm_concatvec, devel_set))"
   ],
   "metadata": {
    "id": "T7kMhdNnc2Gp"
   },
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score SVM concatenacion de vectores:  0.4121280805187426\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "# SVM Mean Vector Entrenamiento\n",
    "\n",
    "clf_svm_mean_vector_sin_stop_words_preproc = entrenar_svm_mean_vector(cantidad_entradas_vec_tuit,True,True, train_set)\n",
    "clf_svm_mean_vector_sin_stop_words = entrenar_svm_mean_vector(cantidad_entradas_vec_tuit,True,False, train_set)\n",
    "clf_svm_mean_vector_preproc = entrenar_svm_mean_vector(cantidad_entradas_vec_tuit,False,True, train_set)\n",
    "clf_svm_mean_vector = entrenar_svm_mean_vector(cantidad_entradas_vec_tuit,False,False, train_set)\n",
    "\n",
    "clf_svm_mean_vector_sin_stop_words_preproc_agrandado = entrenar_svm_mean_vector(cantidad_entradas_vec_tuit,True,True, entrenamiento_agrandado)\n",
    "clf_svm_mean_vector_sin_stop_words_agrandado = entrenar_svm_mean_vector(cantidad_entradas_vec_tuit,True,False, entrenamiento_agrandado)\n",
    "clf_svm_mean_vector_preproc_agrandado = entrenar_svm_mean_vector(cantidad_entradas_vec_tuit,False,True, entrenamiento_agrandado)\n",
    "clf_svm_mean_vector_agrandado = entrenar_svm_mean_vector(cantidad_entradas_vec_tuit,False,False, entrenamiento_agrandado)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# SVM Mean Vector\n",
    "headers = ['Sin SW', 'Pre-procesado', 'Macro F1']\n",
    "res = []\n",
    "\n",
    "macro_F1_svm_mean_vector_sin_stop_words_pre_proc = macro_F1_mean_vector(cantidad_entradas_vec_tuit,True,True, clf_svm_mean_vector_sin_stop_words_preproc, devel_set)\n",
    "res.append([\"Sí\",\"Sí\", macro_F1_svm_mean_vector_sin_stop_words_pre_proc])\n",
    "\n",
    "macro_F1_svm_mean_vector_sin_stop_words = macro_F1_mean_vector(cantidad_entradas_vec_tuit,True,False, clf_svm_mean_vector_sin_stop_words, devel_set)\n",
    "res.append([\"Sí\",\"No\", macro_F1_svm_mean_vector_sin_stop_words])\n",
    "\n",
    "macro_F1_svm_mean_vector_sin_preproc = macro_F1_mean_vector(cantidad_entradas_vec_tuit,False,True, clf_svm_mean_vector_preproc, devel_set)\n",
    "res.append([\"No\",\"Sí\", macro_F1_svm_mean_vector_sin_preproc])\n",
    "\n",
    "macro_F1_svm_mean_vector = macro_F1_mean_vector(cantidad_entradas_vec_tuit,False,False,clf_svm_mean_vector, devel_set)\n",
    "res.append([\"No\",\"No\", macro_F1_svm_mean_vector])\n",
    "\n",
    "print(\"Pruebas con SVM Mean Vector entrenando en train_set\")\n",
    "print(tabulate(res, headers=headers, tablefmt='fancy_grid'))\n",
    "\n",
    "# SVM Mean Vector agrandando el conjunto de entrenamiento\n",
    "res = []\n",
    "\n",
    "macro_F1_svm_mean_vector_sin_stop_words_pre_proc_agrandado = macro_F1_mean_vector(cantidad_entradas_vec_tuit,True,True, clf_svm_mean_vector_sin_stop_words_preproc_agrandado, test_set)\n",
    "res.append([\"Sí\",\"Sí\", macro_F1_svm_mean_vector_sin_stop_words_pre_proc_agrandado])\n",
    "\n",
    "macro_F1_svm_mean_vector_sin_stop_words_agrandado = macro_F1_mean_vector(cantidad_entradas_vec_tuit,True,False, clf_svm_mean_vector_sin_stop_words_agrandado, test_set)\n",
    "res.append([\"Sí\",\"No\", macro_F1_svm_mean_vector_sin_stop_words_agrandado])\n",
    "\n",
    "macro_F1_svm_mean_vector_sin_pre_proc_agrandado = macro_F1_mean_vector(cantidad_entradas_vec_tuit,False,True, clf_svm_mean_vector_preproc_agrandado, test_set)\n",
    "res.append([\"No\",\"Sí\", macro_F1_svm_mean_vector_sin_pre_proc_agrandado])\n",
    "\n",
    "macro_F1_svm_mean_vector_agrandado = macro_F1_mean_vector(cantidad_entradas_vec_tuit,False,False,clf_svm_mean_vector_agrandado, test_set)\n",
    "res.append([\"No\",\"No\", macro_F1_svm_mean_vector_agrandado])\n",
    "\n",
    "print(\"Pruebas con SVM Mean Vector entrenando en train_set+devel_set (probado en test_set)\")\n",
    "print(tabulate(res, headers=headers, tablefmt='fancy_grid'))"
   ],
   "metadata": {
    "id": "lw7Qw5mic34T"
   },
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruebas con SVM Mean Vector entrenando en train_set\n",
      "╒══════════╤═════════════════╤════════════╕\n",
      "│ Sin SW   │ Pre-procesado   │   Macro F1 │\n",
      "╞══════════╪═════════════════╪════════════╡\n",
      "│ Sí       │ Sí              │   0.615335 │\n",
      "├──────────┼─────────────────┼────────────┤\n",
      "│ Sí       │ No              │   0.607947 │\n",
      "├──────────┼─────────────────┼────────────┤\n",
      "│ No       │ Sí              │   0.589528 │\n",
      "├──────────┼─────────────────┼────────────┤\n",
      "│ No       │ No              │   0.588391 │\n",
      "╘══════════╧═════════════════╧════════════╛\n",
      "Pruebas con SVM Mean Vector entrenando en train_set+devel_set (probado en test_set)\n",
      "╒══════════╤═════════════════╤════════════╕\n",
      "│ Sin SW   │ Pre-procesado   │   Macro F1 │\n",
      "╞══════════╪═════════════════╪════════════╡\n",
      "│ Sí       │ Sí              │   0.604831 │\n",
      "├──────────┼─────────────────┼────────────┤\n",
      "│ Sí       │ No              │   0.60103  │\n",
      "├──────────┼─────────────────┼────────────┤\n",
      "│ No       │ Sí              │   0.610811 │\n",
      "├──────────┼─────────────────┼────────────┤\n",
      "│ No       │ No              │   0.606212 │\n",
      "╘══════════╧═════════════════╧════════════╛\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "# Ensamblado de votación con SVM y MLP Entrenamiento\n",
    "clf_ensamblado_votacion_svm_mlp_sin_stop_words_preproc = entrenar_ensamblado_de_votacion_svm_mlp(cantidad_entradas_vec_tuit, True, True, train_set)\n",
    "clf_ensamblado_votacion_svm_mlp_sin_stop_words = entrenar_ensamblado_de_votacion_svm_mlp(cantidad_entradas_vec_tuit, True, False, train_set)\n",
    "clf_ensamblado_votacion_svm_mlp_preproc = entrenar_ensamblado_de_votacion_svm_mlp(cantidad_entradas_vec_tuit, False, True, train_set)\n",
    "clf_ensamblado_votacion_svm_mlp = entrenar_ensamblado_de_votacion_svm_mlp(cantidad_entradas_vec_tuit, False, False, train_set)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensamblado de votación entre SVM y MLP\n",
      "╒══════════╤═════════════════╤════════════╕\n",
      "│ Sin SW   │ Pre-procesado   │   Macro F1 │\n",
      "╞══════════╪═════════════════╪════════════╡\n",
      "│ Sí       │ Sí              │   0.585081 │\n",
      "├──────────┼─────────────────┼────────────┤\n",
      "│ Sí       │ No              │   0.5879   │\n",
      "├──────────┼─────────────────┼────────────┤\n",
      "│ No       │ Sí              │   0.585909 │\n",
      "├──────────┼─────────────────┼────────────┤\n",
      "│ No       │ No              │   0.585845 │\n",
      "╘══════════╧═════════════════╧════════════╛\n"
     ]
    }
   ],
   "source": [
    "# Ensamblado de votación con SVM y MLP\n",
    "headers = ['Sin SW', 'Pre-procesado', 'Macro F1']\n",
    "res = []\n",
    "\n",
    "macro_F1_ensamblado_votacion_svm_mlp_sin_stop_words_preproc = macro_F1_mean_vector(cantidad_entradas_vec_tuit,True,True, clf_ensamblado_votacion_svm_mlp_sin_stop_words_preproc, test_set)\n",
    "res.append([\"Sí\",\"Sí\", macro_F1_ensamblado_votacion_svm_mlp_sin_stop_words_preproc])\n",
    "\n",
    "macro_F1_ensamblado_votacion_svm_mlp_sin_stop_words = macro_F1_mean_vector(cantidad_entradas_vec_tuit,True,False, clf_ensamblado_votacion_svm_mlp_sin_stop_words, test_set)\n",
    "res.append([\"Sí\",\"No\", macro_F1_ensamblado_votacion_svm_mlp_sin_stop_words])\n",
    "\n",
    "macro_F1_ensamblado_votacion_svm_mlp_preproc  = macro_F1_mean_vector(cantidad_entradas_vec_tuit,False,True, clf_ensamblado_votacion_svm_mlp_preproc, test_set)\n",
    "res.append([\"No\",\"Sí\", macro_F1_ensamblado_votacion_svm_mlp_preproc])\n",
    "\n",
    "macro_F1_ensamblado_votacion_svm_mlp  = macro_F1_mean_vector(cantidad_entradas_vec_tuit,False,False,clf_ensamblado_votacion_svm_mlp, test_set)\n",
    "res.append([\"No\",\"No\", macro_F1_ensamblado_votacion_svm_mlp])\n",
    "\n",
    "print(\"Ensamblado de votación entre SVM y MLP\")\n",
    "print(tabulate(res, headers=headers, tablefmt='fancy_grid'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hiperparámetros"
   ],
   "metadata": {
    "id": "abBp1Qmsdnsq"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "def encontrar_mejor_hiperparametros(cantidad_entradas_vec, corpus, parametros):\n",
    "    parametros_busqueda = {\n",
    "        'svc__C': parametros,\n",
    "        'svc__kernel': ['linear', 'rbf', 'sigmoid']\n",
    "    }\n",
    "    clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "    grid_search = GridSearchCV(clf, parametros_busqueda)\n",
    "    datos, polaridad = generar_datos_polaridad_mean_vector_we(cantidad_entradas_vec, True, False, corpus)\n",
    "    grid_search.fit(datos, polaridad)\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "def buscar_mejor_hiperparametros_en_intervalo(cantidad_entradas_vec, corpus, param_1, param_2, limite):\n",
    "    mejor_param = 0\n",
    "    mejor_clf = 0\n",
    "    for i in range(limite):\n",
    "        print(\"Buscando mejor paramétro entre: \", param_1, param_2)\n",
    "        mejor_clf = encontrar_mejor_hiperparametros(cantidad_entradas_vec, corpus, [param_1, param_2])\n",
    "        mejor_param = mejor_clf[1].C\n",
    "        print(\"El mejor clasificador es: \", mejor_clf)\n",
    "\n",
    "        if mejor_param == param_2:\n",
    "            peor_param = param_1\n",
    "        else:\n",
    "            peor_param = param_2\n",
    "\n",
    "        if mejor_param > peor_param:\n",
    "            medio = (mejor_param - peor_param)/2 + peor_param\n",
    "        else:\n",
    "            medio = (peor_param - mejor_param)/2 + mejor_param\n",
    "\n",
    "        param_1 = mejor_param\n",
    "        param_2 = medio\n",
    "\n",
    "\n",
    "    return mejor_param, mejor_clf\n",
    "\n",
    "mejor_c, mejor_modelo = buscar_mejor_hiperparametros_en_intervalo(256, train_set, 1,0.01, 10)"
   ],
   "metadata": {
    "id": "F8y4fTJbdqPs"
   },
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando mejor paramétro entre:  1 0.01\n",
      "El mejor clasificador es:  Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('svc', SVC(C=1, gamma='auto'))])\n",
      "Buscando mejor paramétro entre:  1 0.505\n",
      "El mejor clasificador es:  Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('svc', SVC(C=1, gamma='auto'))])\n",
      "Buscando mejor paramétro entre:  1 0.7525\n",
      "El mejor clasificador es:  Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('svc', SVC(C=0.7525, gamma='auto'))])\n",
      "Buscando mejor paramétro entre:  0.7525 0.87625\n",
      "El mejor clasificador es:  Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('svc', SVC(C=0.7525, gamma='auto'))])\n",
      "Buscando mejor paramétro entre:  0.7525 0.814375\n",
      "El mejor clasificador es:  Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('svc', SVC(C=0.814375, gamma='auto'))])\n",
      "Buscando mejor paramétro entre:  0.814375 0.7834375\n",
      "El mejor clasificador es:  Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('svc', SVC(C=0.814375, gamma='auto'))])\n",
      "Buscando mejor paramétro entre:  0.814375 0.7989062499999999\n",
      "El mejor clasificador es:  Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('svc', SVC(C=0.814375, gamma='auto'))])\n",
      "Buscando mejor paramétro entre:  0.814375 0.806640625\n",
      "El mejor clasificador es:  Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('svc', SVC(C=0.806640625, gamma='auto'))])\n",
      "Buscando mejor paramétro entre:  0.806640625 0.8105078125\n",
      "El mejor clasificador es:  Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('svc', SVC(C=0.8105078125, gamma='auto'))])\n",
      "Buscando mejor paramétro entre:  0.8105078125 0.80857421875\n",
      "El mejor clasificador es:  Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('svc', SVC(C=0.80857421875, gamma='auto'))])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Obtener los hiperparámetros utilizados\n",
    "svm = clf_svm_mean_vector.named_steps['svc']  # Obtener el estimador SVM del pipeline\n",
    "C = svm.C  # Obtener el valor de C\n",
    "gamma = svm.gamma  # Obtener el valor de gamma\n",
    "\n",
    "print(f\"El valor de C es {C} y el valor de gamma es {gamma}\")\n",
    "\n",
    "macro_f1_con_mejores_hiperparametros = macro_F1_mean_vector(256,True,True, mejor_modelo, devel_set)\n",
    "print(\"Macro F1 probado en devel_set\", macro_f1_con_mejores_hiperparametros)"
   ],
   "metadata": {
    "id": "SZSxQPH-dtmA"
   },
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor de C es 1.0 y el valor de gamma es auto\n",
      "Macro F1 probado en devel_set 0.6136053723342164\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6VGFrEoWHr3"
   },
   "source": [
    "## Parte 4: Evaluación sobre test\n",
    "\n",
    "Deben probar los mejores modelos obtenidos en la parte anterior sobre el corpus de test.\n",
    "\n",
    "También deben comparar sus resultados con un modelo pre-entrenado para análisis de sentimientos de la biblioteca [pysentimiento](https://github.com/pysentimiento/pysentimiento) (deben aplicarlo sobre el corpus de test).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score pysentimiento 0.7041227233971533\n"
     ]
    }
   ],
   "source": [
    "# Pysentimiento\n",
    "def macro_F1_pysentimiento(corpus):\n",
    "    analyzer = create_analyzer(task=\"sentiment\", lang=\"es\")\n",
    "    y_pred = []\n",
    "    y_real = [elem[2] for elem in corpus]\n",
    "    for elemento in corpus:\n",
    "        analizer_result = analyzer.predict(elemento[1]).output\n",
    "        y_pred.append(sentimiento_map[analizer_result])\n",
    "    return f1_score(y_real, y_pred, average=\"macro\")\n",
    "\n",
    "print(\"F1 Score pysentimiento\", macro_F1_pysentimiento(test_set))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruebas MLP sobre test_set\n",
      "╒══════════╤═════════════════╤════════════╕\n",
      "│ Sin SW   │ Pre-procesado   │   Macro F1 │\n",
      "╞══════════╪═════════════════╪════════════╡\n",
      "│ Sí       │ Sí              │   0.558917 │\n",
      "├──────────┼─────────────────┼────────────┤\n",
      "│ Sí       │ No              │   0.56165  │\n",
      "├──────────┼─────────────────┼────────────┤\n",
      "│ No       │ Sí              │   0.556806 │\n",
      "├──────────┼─────────────────┼────────────┤\n",
      "│ No       │ No              │   0.551947 │\n",
      "╘══════════╧═════════════════╧════════════╛\n"
     ]
    }
   ],
   "source": [
    "# Evaluación sobre test MLP\n",
    "\n",
    "print(\"Pruebas MLP sobre test_set\")\n",
    "res = []\n",
    "headers = ['Sin SW', 'Pre-procesado', 'Macro F1']\n",
    "\n",
    "macro_f1_mlp_mean_vector_sin_stop_words_pre_proc = macro_F1_mean_vector(cantidad_entradas_vec_tuit, True, True, clf_mlp_mean_vector_sin_stop_words_preproc, test_set)\n",
    "res.append([\"Sí\",\"Sí\", macro_f1_mlp_mean_vector_sin_stop_words_pre_proc])\n",
    "\n",
    "macro_f1_mlp_mean_vector_sin_stop_words = macro_F1_mean_vector(cantidad_entradas_vec_tuit,True,False, clf_mlp_mean_vector_sin_stop_words, test_set)\n",
    "res.append([\"Sí\", \"No\", macro_f1_mlp_mean_vector_sin_stop_words])\n",
    "\n",
    "macro_f1_mlp_mean_vector_pre_proc =  macro_F1_mean_vector(cantidad_entradas_vec_tuit,False,True, clf_mlp_mean_vector_preproc, test_set)\n",
    "res.append([\"No\", \"Sí\", macro_f1_mlp_mean_vector_pre_proc])\n",
    "\n",
    "macro_f1_mlp_mean_vector = macro_F1_mean_vector(cantidad_entradas_vec_tuit,False,False,clf_mlp_mean_vector, test_set)\n",
    "res.append([\"No\", \"No\", macro_f1_mlp_mean_vector])\n",
    "\n",
    "print(tabulate(res, headers=headers, tablefmt='fancy_grid'))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruebas SVM Mean Vector sobre test_set\n",
      "╒══════════╤═════════════════╤════════════╕\n",
      "│ Sin SW   │ Pre-procesado   │   Macro F1 │\n",
      "╞══════════╪═════════════════╪════════════╡\n",
      "│ Sí       │ Sí              │   0.607559 │\n",
      "├──────────┼─────────────────┼────────────┤\n",
      "│ Sí       │ No              │   0.601875 │\n",
      "├──────────┼─────────────────┼────────────┤\n",
      "│ No       │ Sí              │   0.609586 │\n",
      "├──────────┼─────────────────┼────────────┤\n",
      "│ No       │ No              │   0.608642 │\n",
      "╘══════════╧═════════════════╧════════════╛\n",
      "Pruebas con Mean Vector entrenando en train_set+devel_set\n",
      "╒══════════╤═════════════════╤════════════╕\n",
      "│ Sin SW   │ Pre-procesado   │   Macro F1 │\n",
      "╞══════════╪═════════════════╪════════════╡\n",
      "│ Sí       │ Sí              │   0.604831 │\n",
      "├──────────┼─────────────────┼────────────┤\n",
      "│ Sí       │ No              │   0.60103  │\n",
      "├──────────┼─────────────────┼────────────┤\n",
      "│ No       │ Sí              │   0.610811 │\n",
      "├──────────┼─────────────────┼────────────┤\n",
      "│ No       │ No              │   0.606212 │\n",
      "╘══════════╧═════════════════╧════════════╛\n",
      "Macro F1 probado en test_set con los hiperparámetros mejorados:  0.607014455759271\n"
     ]
    }
   ],
   "source": [
    "# Prueba SVM Mean Vector sobre test_set\n",
    "headers = ['Sin SW', 'Pre-procesado', 'Macro F1']\n",
    "res = []\n",
    "\n",
    "macro_F1_svm_mean_vector_sin_stop_words_preproc = macro_F1_mean_vector(cantidad_entradas_vec_tuit,True,True, clf_svm_mean_vector_sin_stop_words_preproc, test_set)\n",
    "res.append([\"Sí\",\"Sí\", macro_F1_svm_mean_vector_sin_stop_words_preproc])\n",
    "\n",
    "macro_F1_svm_mean_vector_sin_stop_words = macro_F1_mean_vector(cantidad_entradas_vec_tuit,True,False, clf_svm_mean_vector_sin_stop_words, test_set)\n",
    "res.append([\"Sí\",\"No\", macro_F1_svm_mean_vector_sin_stop_words])\n",
    "\n",
    "macro_F1_svm_mean_vector_sin_preproc = macro_F1_mean_vector(cantidad_entradas_vec_tuit,False,True, clf_svm_mean_vector_preproc, test_set)\n",
    "res.append([\"No\",\"Sí\", macro_F1_svm_mean_vector_sin_preproc])\n",
    "\n",
    "macro_F1_svm_mean_vector = macro_F1_mean_vector(cantidad_entradas_vec_tuit,False,False,clf_svm_mean_vector, test_set)\n",
    "res.append([\"No\",\"No\", macro_F1_svm_mean_vector])\n",
    "\n",
    "print(\"Pruebas SVM Mean Vector sobre test_set\")\n",
    "print(tabulate(res, headers=headers, tablefmt='fancy_grid'))\n",
    "\n",
    "# SVM Mean Vector agrandando el conjunto de entrenamiento\n",
    "res = []\n",
    "\n",
    "res.append([\"Sí\",\"Sí\", macro_F1_svm_mean_vector_sin_stop_words_pre_proc_agrandado])\n",
    "\n",
    "res.append([\"Sí\",\"No\", macro_F1_svm_mean_vector_sin_stop_words_agrandado])\n",
    "\n",
    "res.append([\"No\",\"Sí\", macro_F1_svm_mean_vector_sin_pre_proc_agrandado])\n",
    "\n",
    "res.append([\"No\",\"No\", macro_F1_svm_mean_vector_agrandado])\n",
    "\n",
    "print(\"Pruebas con Mean Vector entrenando en train_set+devel_set\")\n",
    "print(tabulate(res, headers=headers, tablefmt='fancy_grid'))\n",
    "\n",
    "macro_f1_con_mejores_hiperparametros = macro_F1_mean_vector(256,True,True, mejor_modelo, test_set)\n",
    "print(\"Macro F1 probado en test_set con los hiperparámetros mejorados: \",macro_f1_con_mejores_hiperparametros)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desglose de la mejor estrategia (SVM Mean Vector) mostrando su comportamiento en cada clase (métrica: exactitud)\n",
      "╒════════════╤═════════════╕\n",
      "│ Conjunto   │   Exactitud │\n",
      "╞════════════╪═════════════╡\n",
      "│ Positivos  │    0.658842 │\n",
      "├────────────┼─────────────┤\n",
      "│ Negativos  │    0.676871 │\n",
      "├────────────┼─────────────┤\n",
      "│ Neutros    │    0.497717 │\n",
      "╘════════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "# Puntuación por clase\n",
    "headers = ['Conjunto','Exactitud']\n",
    "res = []\n",
    "\n",
    "def obtener_tuits_por_clase(corpus):\n",
    "    positivos = []\n",
    "    negativos = []\n",
    "    neutros = []\n",
    "    for tuit in corpus:\n",
    "        if tuit[2] == 'P':\n",
    "            positivos.append(tuit)\n",
    "        if tuit[2] == 'N':\n",
    "            negativos.append(tuit)\n",
    "        if tuit[2] == 'NONE':\n",
    "            neutros.append(tuit)\n",
    "    return positivos, negativos, neutros\n",
    "\n",
    "tuits_positivos, tuits_negativos, tuits_neutros = obtener_tuits_por_clase(test_set)\n",
    "accuracy_positivos= accuracy_score_mean_vector(cantidad_entradas_vec_tuit,False,True,clf_svm_mean_vector, tuits_positivos)\n",
    "accuracy_negativos = accuracy_score_mean_vector(cantidad_entradas_vec_tuit,False,True,clf_svm_mean_vector, tuits_negativos)\n",
    "accuracy_neutros = accuracy_score_mean_vector(cantidad_entradas_vec_tuit,False,True,clf_svm_mean_vector, tuits_neutros)\n",
    "\n",
    "print(\"Desglose de la mejor estrategia (SVM Mean Vector) mostrando su comportamiento en cada clase (métrica: exactitud)\")\n",
    "res.append([\"Positivos\", accuracy_positivos])\n",
    "res.append([\"Negativos\", accuracy_negativos])\n",
    "res.append([\"Neutros\", accuracy_neutros])\n",
    "\n",
    "\n",
    "print(tabulate(res, headers=headers, tablefmt='fancy_grid'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preguntas finales\n",
    "\n",
    "Responda las siguientes preguntas:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1) ¿Qué modelos probaron para la representación de los tweets?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Probamos distintas representaciones de Bag of Words (en adelante BoW) y de Word Embeddings (en adelante WE).\n",
    "\n",
    "Entre las representaciones de BoW aplicamos el Estándar, filtramos stop-stop words, y combinamos con TF-IDF que mide la relevancia de una palabra con respecto al texto que lo contiene, para luego asignarle un factor de ponderación.\n",
    "\n",
    "Con respecto a WE utilizamos dos enfoques diferentes: el primero es obteniendo la mediana del valor de las palabras que conforman un tweet (Mean Vector). El segundo es concatenación de vectores, en el que se genera una lista con la concatenación de los valores de las palabras de los tweets (Concat Vec)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2) ¿Aplicaron algún tipo de preprocesamiento de los textos?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "En varios de los experimentos aplicamos prerpocesamiento, entre estas tareas se incluye: reemplazo de identificadores de usuario y Hashtags por tags genéricos y mejora de ortografía. Por lo general, la diferencia entre trabajar con un corpus preprocesado y no preprocesado representa una diferencia en macro F1 de menos de 1%.\n",
    "\n",
    "A modo de ejemplo: en SVM Mean Vector sin preprocesamiento el macro F1 dió 0,5919, mientras que la misma técnica con prepoc dió 0,5875. En este caso el preprocesamiento empeoró el resultado.\n",
    "\n",
    "Sin embargo, si eliminamos las Stop-Words y aplicamos esa misma técnica: vemos que sin preproc el resultado es 0,5958, mientras que con un corpus prepocesado el resultado es 0,6001. Por lo que en este caso, la etapa de preprocesado mejoró la medida."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3) ¿Qué modelos de aprendizaje automático probaron?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "En el desarrollo del laboratorio se generaron distantas tablas mostrando la performance de las distintas estrategias utilizadas con su respectiva representación. La información disponible permite hacer comparaciones directas entre ellas, por lo que en esta sección serán referenciadas extensivamente.\n",
    "\n",
    "Las estrategias utilizadas fueron:\n",
    "\n",
    "*   Multi Layer Perceptron (MLP)\n",
    "Las redes neuronales MLP están compuesta por múltiples capas de neuronas interconectadas.\n",
    "\n",
    "Este enfoque no tuvo el mejor desempeño en esta tarea, llegando a una puntuación F1 de 0,56. Por más de que no fue el enfoque en el cuál se obtuvieron los mejores resultados en devel, decidimos probarlo con el corpus de prueba para ver si habían cambios sustantivos en el resultado, sin mucho éxito.\n",
    "\n",
    "Nuestros experimentos con MLP fueron realizados en ambas representaciones (BoW y WE) y\n",
    "\n",
    "*   Support Vector Machines (SVM):\n",
    "\n",
    "En forma simplifacada, en este modelo los tweets son reperesentados como puntos en el espacio. En el entrenamiento se busca encontrar un hiperplano que separe los tweets de acuerdo a la clasificación dada.\n",
    "\n",
    "Experimentamos con ambas versiones de WE de los tweets (MV y concat). Implementamos una búsqueda automática de hiperparámetros, pero los resultados de esta no fueron suficientes para superar los parámetros por defecto (C=1, kernel=\"linear\"). La forma que se realizó la búsqueda fue utilizando un método de bipartición, se sospecha que la función que relaciona a los HP con el score parece no ser continua, pero no hay evidencia para afirmarlo.\n",
    "\n",
    "Los resultados de los experimentos fueron evaluados por el grupo de forma positiva, llegando a\n",
    "\n",
    "*   LSTM:\n",
    "\n",
    "Este enfoque será detallado en la pregunta 5."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4) ¿Qué atributos utilizaron para estos modelos?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para las tres estrategias definimos dos _«parámetros»_ vinculados con el prepocesamiento y la eliminación de stop-words en el corpus. En las tablas se puede ver las distintas combinaciones y sus resultados, vimos que no hay una correlación clara entre una puntuación superior con alguna de las combinaciones en particular. Además, vemos que la puntuación varía en un margen muy pequeño cuando se varían estos parámetros (no más de 1%).\n",
    "\n",
    "Por otro lado, para SVM implementamos una búsqueda automática de hiperparámetros, pero los resultados de esta no fueron suficientes para superar los parámetros por defecto (C=1, kernel=\"linear\"). La forma que se realizó la búsqueda fue utilizando un método de bipartición, se sospecha que la función que relaciona a los HP con el score no es continua, pero no hay evidencia para afirmarlo. Es importante tener en cuenta que las pruebas sobre los hiperparametros se hicieron con la representación mean vector con vectores de tamaño 256 en vez de 300 (como se realizó en el resto de las pruebas), ya que un vector tan grande hizo que demorara un tiempo excesivo la búsqueda de parámetros.\n",
    "\n",
    "Por último, buscamos parámetros utilizando heurísticas para mejorar los resultados, sin obtener éxito en los casos de SVM y MLP. Los parámetros por default fueron los que tuvieron mejores resultados en todos los casos.\n",
    "\n",
    "Para LSTM realizamos tanto búsqueda automática como búsqueda manual, esto será detallado en la pregunta 6."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5) ¿Probaron algún enfoque de aprendizaje profundo?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sí, trabajamos con Long Short-Term Memory (LSTM).\n",
    "Con fines de prolijidad, en el Laboratorio solamente dejamos la configuración que dio mejores resultados. Se generó una red con varias capas densas, se realizaron varias pruebas variando el tamaño de las capas para poder elegir la que funcione mejor. Después de las pruebas la red resultante fue bastante simple y no mostró un desempeño destacado entre los otros modelos, fue el que funcionó peor. La máxima puntuación F1 lograda fue 0.324333, apenas pasando la mitad de la medida alcanzada por la mejor estrategia."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6) ¿Probaron diferentes configuraciones de hiperparámetros?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Las pruebas en LSTM se realizaron variando el tamaño de las capas, cambiando el tamaño de los batches en los que se fue aprendiendo el conjunto de entrenamiento y la cantidad de épocas. Otra prueba realizada que no mostró una mejoría en el resultado final fue agregando capas de \"Dropout\" donde solo un porcentaje de las neuronas llegaran activas a la siguiente capa, esto se hace para reducir el sobre ajuste.\n",
    "Las pruebas cambiando la cantidad de neuronas de una capa se realizaron a través de un paramétro de entrada en la función que genera el modelo, ese parametro se colocó en lugar de la cantidad de neuronas de la capa y se generaron varios modelos calculando para cada uno su puntaje macro F1, para así poder elegir el que funcione mejor. De la misma forma se ejecutaron las pruebas con las capas dropout.\n",
    "Otro parámetro que fue modificado fue el tamaño del vector de entrada, se observó que un vector de tamaño 256 fue el que dio mejor resultado."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7) ¿Qué enfoque (preprocesamiento + representación de tweets + modelo + atributos/parámetros) obtuvo la mejor Macro-F1?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Representación de Tweets: WE - Mean Vector\n",
    "\n",
    "Embedding utilizado: embeddings-l-model.vec\n",
    "Modelo: SVM\n",
    "\n",
    "Atributos/Parámetros:\n",
    "\n",
    "Sin stop-words: False\n",
    "Corpus preprocesado: True\n",
    "Macro F1 = 0.609586\n",
    "\n",
    "Nota importante: Uno de nuestros experimientos se basó en fusionar el devel_set con el train_set para generar un corpus de entrenamiento más grande para ver si esto influía en el resultado final. Con este nuevo corpus utilizamos la estrategia de SVM Mean Vector y MLP. El resultado fue un incremento llegando al recórd del grupo con 0.610811. La diferencia entre este enfoque y su contraparte solo entrenada con el train_set es de 0.001225. Entendemos que la idea de la tarea es utilizar correctamente las tres particiones del corpus, sin embargo nos pareció interesante mostrar este resultado destacando que aumentando el tamaño del corpus los resultados mejoraron (muy poco).\n",
    "\n",
    "Los datos específicos de este experimento son:\n",
    "\n",
    "Representación de Tweet: WE - Mean Vector\n",
    "\n",
    "Modelo: SVM\n",
    "\n",
    "Corpus de entrenamiento: train_set + devel_set\n",
    "\n",
    "Embedding utilizado: embeddings-l-model.vec\n",
    "Atributos/Parámetros:\n",
    "\n",
    "Sin stop-words = False\n",
    "Corpus preprocesado = True\n",
    "Macro F1 = 0.610811"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 8) ¿Qué clase es la mejor clasificada por este enfoque? ¿Cuál es la peor? ¿Por qué piensan que sucede esto?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Utilizamos la Exactitud (predicciones correctas / predicciones totales) sobre cada clase separada para obtener métricas sobre la performance de cada una. Los resultados se pueden observar en la tabla correspondiente.\n",
    "\n",
    "La clase mejor clasificada fueron los Tweets Negativos con 0.67871 y muy cerca los Tweets Positivos con 0,658842. Por otro lado, la peor clasificada fueron los Tweets Neutros, con una exactitud de 0.49717.\n",
    "\n",
    "Creemos que esto sucede por las siguientes razones:\n",
    "- A diferencia de los tweets positivos o negativos, que pueden contener palabras fuertemente emocionales que «muevan la aguja» para un polo u otro, los tweets neutrales pueden carecer de señales claras de polaridad.\n",
    "- La polaridad de un tweet puede depender del contexto en el que se utilice. Una misma frase puede interpretarse como neutra en un contexto, pero como positiva o negativa en otro."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 9) ¿Cómo son sus resultados en comparación con los de pysentimiento? ¿Por qué piensan que sucede esto?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nuestros resultados son inferiores a los de pysentimiento por un márgen aproximado de 10% a 15% dependiendo del enfoque, creemos que esto se debe a las siguientes razones:\n",
    "\n",
    "1. Nuestros modelos son entrenados en base a tweets: Como fue identificado en la tarea anterior, los tweets tienen dos grandes problemas: El primero de ellos se debe a las faltas ortografía y el uso indebido o informal del lenguaje. Esto lleva a que estrategias como BoW Estándar y BoW TF-IDF pierdan efectividad y eficacia, ya que al tener una misma palabra escrita de varias formas se pierde la escencia del multiconjunto.\n",
    "\n",
    "   Este problema afecta también a la estrategia WE, ya que el embedding utilizado no solo sucede que las palabras mal escritas no están en el embedding, sino que hay algunas pablaras correctas que simplemente no están representadas en el embedding. Esto, en definitiva, es equivalente afirmar que aquellas palabras no representadas en el embedding es como si no estuviesen estén en el tweet.\n",
    "\n",
    "  Por otro lado: el segundo problema de los tweets son su longitud y consecuente falta de contexto. Los tweets están limitados a 280 caracteres, lo que hace que la cantidad de información disponible para el entrenamiento sea limitada.\n",
    "\n",
    "2. A pesar de estar entrenados con el mismo corpus (TASS 2020) la librería pysentimiento utiliza una variante de BERT (RoBERTuito). Por lo que entendimos de la documentación, RoBERTuito es un modelo pre-entrenado en más de 500 millones de tweets, esto marca una ventaja cuantitativa en la etapa de entrenamiento para pysentimiento que explicaría la diferencia en la medida F1.\n",
    "\n",
    "  Como fue mencionado en la respuesta 7: uno de nuestros experimientos se basó en fusionar el devel_set con el train_set para generar un corpus de entrenamiento más grande para ver si esto influía en el resultado final. El resultado fue un incremento de 2 puntos llegando al recórd del grupo con 61,08%. Este resultado es conclusivo y reafirma algo evidente: el tamañano del corpus es relevante, por lo que pre-entrenar sobre 500 millones de tweets marca una ventaja sustantiva.\n",
    "\n",
    "  BERT despertó nuestra curiosidad para experimentar con él, pero dado que viene pre-entrenado, entendimos que no es la esencia de esta tarea trabajar con este tipo de modelo de redes neuronales.\n",
    "\n",
    "3. Al igual que el implementado por nosotros, Pysentimiento incluye un preprocesador de texto que reemplaza los identificadores de usuario y las URL por tokens especiales. Sin embargo, tiene otras funcionalidades como por ejemplo acortar caracteres repetidos y separar hasthags por palabras correctamente. El método _preprocess_tweet()_ de pysentimiento cuenta con 11 parámetros para configurar el tipo de preprocesado. Esto muestra que el preprocesador de la librería es mucho más sofisticado que el nuestro."
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  File \u001B[1;32m<tokenize>:7\u001B[1;36m\u001B[0m\n\u001B[1;33m    Por otro lado: el segundo problema de los tweets son su longitud y consecuente falta de contexto. Los tweets están limitados a 280 caracteres, lo que hace que la cantidad de información disponible para el entrenamiento sea limitada.\u001B[0m\n\u001B[1;37m    ^\u001B[0m\n\u001B[1;31mIndentationError\u001B[0m\u001B[1;31m:\u001B[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "execution_count": 99
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": [
    "Ctp40-YxvUOM",
    "abBp1Qmsdnsq"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
